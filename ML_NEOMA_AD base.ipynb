{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legendary-heading",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Paysim dataset description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-january",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Synthetic dataset. Recorded transactions in a agent-based simulation of a financial system augmented with anonimized real financial data.\n",
    "\n",
    "Private nature of financial transactions -> there are few publicly available datasets\n",
    " \n",
    "More info at https://www.kaggle.com/ntnu-testimon/paysim1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-triple",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Your plan for this experiment could look like this : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-camera",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "    0) Install all dependancies, configure the environement, etc \n",
    "    1) Look at the data \n",
    "    2) What is our goal? classification/regression/outlier detection/... \n",
    "    3) Decide what's important and what's not. What could help us to classify/predict/... better ?\n",
    "    4) Choose the columns \n",
    "    5) Define the preprocessing for theese columns (based on their type)\n",
    "    6) Define how we will measure the performance of future model. Evaluation metrics.\n",
    "    7) Split the data in train/test subsets ( + validation set if we want to use smth like EarlyStopping)\n",
    "    8) Apply the preprocessing\n",
    "    9) Build a simple model (using the train subset)\n",
    "    10) Save model via Pickle to accelerate the research\n",
    "    11) Test the model with the unseen data (test subset)\n",
    "\n",
    "    If the models' performance is not good enough, go to -> 1/2/3/...|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-crack",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Lets start with some common imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "treated-console",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-alert",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Importing the dataset from external csv file (Comma Separated File)\n",
    "dataset = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-aluminum",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-prisoner",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### What's inside our dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-float",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "otherwise-finger",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total nb samples in dataset :  6362620\n"
     ]
    }
   ],
   "source": [
    "nb_classes = dataset['isFraud'].value_counts()\n",
    "print(\"total nb samples in dataset : \", nb_classes.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-affiliation",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Ratio of \"fraudlent\" transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crucial-belly",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001290820448180152"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes.min()/nb_classes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-china",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Ratio of \"regular\" transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compound-backing",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987091795518198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes.max()/nb_classes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-barbados",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "It's a common problem for such datasets -> **imbalanced classes**.   \n",
    "\n",
    "We have 0.1% of samples which correspond to the class \"fraud\" and it could be complicated for most Machine Learning algorithms to extract meaningful information from few samples in the presence of a 99.9% dominant class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-zambia",
   "metadata": {},
   "source": [
    "#### Lets' check the repartition of \"fraud\" by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-reward",
   "metadata": {},
   "source": [
    "Only Cash-out and Transfer transactions could be fraudlent in this example. This could be useful later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-connectivity",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-scholarship",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Data preparation : main ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-connecticut",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Understand column type - if it is categorical/numerical/part of an image/etc ...\n",
    "\n",
    "# In general, categorical columns are transformed to numerical via some trick like One-Hot encoding\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "\n",
    "# On the other side, numerical columns are often standartized to have zero mean and unit variance (avg(x)=0, std(x)=1)\n",
    "# https://stackoverflow.com/questions/26414913\n",
    "# normalized_data=(data-data.mean())/data.std()\n",
    "\n",
    "# All this is explained in great detail here : \n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-exemption",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# We could remove several columns. Often things like IDs, text descriptions could be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-audio",
   "metadata": {},
   "source": [
    "#### Train/test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "above-brisbane",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-calgary",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# split the data: often it's 80% for training and 20% for evaluation (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-blast",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-possession",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# There are a lot of models avaliable in sklearn python library\n",
    "# Linear Regression, Decision Tree, Random Forest, ... \n",
    "# https://sklearn.org/user_guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coordinate-semiconductor",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-process",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# the most important part -> lets' train the model!\n",
    "# model = model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-revelation",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# after that model c.b. used to make predictions.\n",
    "# Important: do not use the same data for training and evaluation. \n",
    "# Such data leak will corrupt the results of your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-desire",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# the second most important part will look like this :\n",
    "# test_prediction_result = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-robinson",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suffering-involvement",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-republican",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# after that, the test_result is compared with actual labels from test_data \n",
    "# cm = confusion_matrix(test_prediction_result, test_real_labels)\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-beginning",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# If it s performing poorly, what could we do about that ?\n",
    "# We could try smth from this list: \n",
    "# feature engineering, another algorithm, bigger/smaller model, more data, another preprocessing, ...\n",
    "# If data is unbablanced:\n",
    "# class_weights with supervised algorithm, undersampling, synthetic samples, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-applicant",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Metrics which could be used in the context of anomaly detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-bridal",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# AUC_PR, AUC_ROC, recall, precision, ...\n",
    "# but not only accuracy\n",
    "# (you could have accuracy 99.9% just by predicting  ALL of the data samples as \"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-relevance",
   "metadata": {},
   "source": [
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-brave",
   "metadata": {},
   "source": [
    "### If you want to try real-world data with real fraud / money laundering : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-minneapolis",
   "metadata": {},
   "source": [
    "https://www.elliptic.co/blog/elliptic-dataset-cryptocurrency-financial-crime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-pepper",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### More advanced techniques for those who s interesed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-robertson",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Neural net model + focal loss : \n",
    "# https://www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/\n",
    "# https://towardsdatascience.com/lightgbm-with-the-focal-loss-for-imbalanced-datasets-9836a9ae00ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-adapter",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# A particular type of neural net, autoencoder\n",
    "# https://keras.io/examples/timeseries/timeseries_anomaly_detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-great",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# to better represent categorical features there are alternatives to one-hot encoding\n",
    "# Emeddings, TargetEncoding, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-yeast",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# aggregate several models into one : \n",
    "# model blending, model stacking, ...\n",
    "# https://www.kaggle.com/anuragbantu/stacking-ensemble-learning-beginner-s-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-disposal",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# c.b. useful - comparison of different Anomaly detection models \n",
    "# https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
